---
title: "Scraping Wikipedia"
author: "Carson Zhang (cxzhang4)"
date: "7/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
pop_artists_page = read_html("https://en.wikipedia.org/wiki/List_of_highest-certified_music_artists_in_the_United_States")
```

```{r}
artists = pop_artists_page %>%
  html_node("table:nth-of-type(2)") %>%
  html_table() %>%
  as_tibble()
```

```{r}
artists %>% 
  glimpse()
```

```{r}
artist_hrefs = pop_artists_page %>%
  html_nodes("table:nth-of-type(2) tbody a[href^=\"/wiki\"]") %>%
  html_attr("href")

artist_hrefs
```

```{r}
wiki_base_url = "https://en.wikipedia.org"
artist_links = paste(wiki_base_url, artist_hrefs, sep = "")

artist_links
```

```{r}
# drake_link = "https://en.wikipedia.org/wiki/Meghan_Trainor"
# 
# drake_page = read_html(drake_link) %>%
#   html_nodes("th.navbox-group:contains(\"Studio albums\")")
# 
# drake_page %>%
#   "["(1)
```

```{r}
# drake_albums = drake_page %>%
#   html_text()
# 
# drake_tbl = tibble(artist = rep("Drake", times = length(drake_albums)),
#                    album = drake_albums)

# genius_albums %>%
#   bind_rows(drake_tbl)
```

```{r}
# artist_underscores = gsub(" ", "_", artists$Name)

get_albums = function(artist_url, artist_name) {
  artist_id = gsub(" ", "_", artist_name)
  # build CSS selector strnig
  big_navbox = paste("div.navbox[aria-labelledby=\"", artist_id, "\"]",
                     sep = "")
  
  album_list = "th.navbox-group:contains(\"tudio albums\") + td i a[href^=\"/wiki/\"]"
  
  selector = paste(big_navbox, album_list, sep = " ")
  
  # print(selector)
  
  album_names = read_html(artist_url) %>%
    # box on bottom of wikipedia page 
    html_nodes(selector) %>%
    # if there are multiple associated acts with studio albums: 
    # first one should be main artist
    # "["(1) %>%
    html_text()
  
  df = tibble(artist = rep(artist_name, times = length(album_names)), 
              album = album_names)
  
  # genius_albums = genius_albums %>%
  #   bind_rows(df)
  df
}
```

```{r}
# genius_albums = tibble(artist = character(), album = character())
```

```{r}
# map2_dfr will do the work of binding the rows togethere
genius_albums = map2_dfr(artist_links, artists$Name, get_albums)
```

```{r}
# artists %>%
#   right_join(genius_albums, by = c("Name" =  "artist"))
```

Scrape singles - use their sentiments as separate feature (allowing it to be weighted differently)

```{r}
# get_singles = function(artist_url, artist_name) {
#   single_names = read_html(artist_url) %>%
#     html_nodes("th.navbox-group:contains(\"Singles\") + 
#              td i a[href^=\"/wiki/\"]") %>%
#     "["(1) %>%
#     html_text()
#   
#   df = tibble(artist = rep(artist_name, times = length(single_names)), 
#               track_title = single_names)
#   
#   df
# }
# 
# singles_df = tibble(artist = character(), track_title = character())
# 
# singles_df = map2_dfr(artist_links, artists$Name, get_singles)
```

## Error check scraping code

```{r}
missing_artists = setdiff(artists$Name, genius_albums$artist)
```

It mostly works: just `r missing_artists` is missing.

Since she just has one album, I'll add it manually.

```{r}
genius_albums = genius_albums %>%
  add_row(artist = "Billie Eilish", album = "When We All Fall Asleep, Where Do We Go?")
```

```{r}
genius_albums %>%
  filter(artist == "Billie Eilish")
```

## Get lyrics from Genius

```{r}
library(genius)

pop_lyrics = genius_albums %>%
  add_genius(artist, album, type = "album")

write_csv(pop_lyrics, "pop_lyrics.csv")
```


